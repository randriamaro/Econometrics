{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import statsmodels.api as sm\n",
    "from numpy.linalg import inv\n",
    "from linearmodels import PanelOLS\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "from numpy.linalg import inv\n",
    "from collections import OrderedDict\n",
    "from linearmodels.panel import compare\n",
    "from linearmodels.panel import PooledOLS\n",
    "\n",
    "import os\n",
    "#cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset \"full merit aid\" contains information on college enrollment by year and by state along with merit and demographics such as gender and race. We are interested in looking at the effect of merit, demographics, year and state fixed effects on college enrollment i.e. \n",
    "\\begin{equation}\n",
    "college_{it} = \\gamma_t + \\alpha_i +\\beta_1 merit_{it} + \\beta_2 male_{it} + \\beta_3 black_{it} + \\beta_4 asian_{it} +  \\epsilon_{it}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Standard regression using all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"fullmeritaiddata.csv\")\n",
    "year = pd.Categorical(df['year'])\n",
    "state = pd.Categorical(df['state'])\n",
    "df = df.set_index(['state','year'])\n",
    "df['year'] = year\n",
    "df['state'] = state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimation using canned package for standard regression for panel data. The estimation uses all of the variables as well as dummy variables for year and state. The standard errors are clustered by state and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated parameters for exogenous variables from standard regression with state and year FE\n",
      "constant: 0.442\n",
      "merit: 0.034\n",
      "male: -0.079\n",
      "black: -0.15\n",
      "asian: 0.169\n"
     ]
    }
   ],
   "source": [
    "exog = ['merit','male','black','asian','year','state']\n",
    "x = sm.add_constant(df[exog])\n",
    "clust_state_year = PanelOLS(df['coll'], x).fit(cov_type='clustered',\n",
    "                cluster_entity=True, cluster_time=True,use_lsdv=True)\n",
    "parameters = clust_state_year.params\n",
    "se_sy = clust_state_year.std_errors\n",
    "print(\"Estimated parameters for exogenous variables \\\n",
    "from standard regression with state and year FE\")\n",
    "print('constant:',np.round(parameters[0],3))\n",
    "print('merit:',np.round(parameters[1],3))\n",
    "print('male:',np.round(parameters[2],3))\n",
    "print('black:',np.round(parameters[3],3))\n",
    "print('asian:',np.round(parameters[4],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard errors clustered by state and year for exogenous variables\n",
      "constant: 0.009\n",
      "merit: 0.012\n",
      "male: 0.008\n",
      "black: 0.014\n",
      "asian: 0.028\n"
     ]
    }
   ],
   "source": [
    "print(\"Standard errors clustered by state and year \\\n",
    "for exogenous variables\")\n",
    "print('constant:',np.round(se_sy[0],3))\n",
    "print('merit:',np.round(se_sy[1],3))\n",
    "print('male:',np.round(se_sy[2],3))\n",
    "print('black:',np.round(se_sy[3],3))\n",
    "print('asian:',np.round(se_sy[4],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Panel regression with standard errors clusterd by state only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard errors clustered by state for exogenous variables\n",
      "constant: 0.009\n",
      "merit: 0.013\n",
      "male: 0.007\n",
      "black: 0.014\n",
      "asian: 0.03\n"
     ]
    }
   ],
   "source": [
    "clust_state = PanelOLS(df.coll, x).fit(cov_type='clustered',\n",
    "                                cluster_entity=True,use_lsdv=True)\n",
    "se_s = clust_state.std_errors\n",
    "print(\"Standard errors clustered by state for exogenous variables\")\n",
    "print('constant:',np.round(se_s[0],3))\n",
    "print('merit:',np.round(se_s[1],3))\n",
    "print('male:',np.round(se_s[2],3))\n",
    "print('black:',np.round(se_s[3],3))\n",
    "print('asian:',np.round(se_s[4],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Robust standard errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robust standard errors for exogenous variables\n",
      "constant: 0.025\n",
      "merit: 0.015\n",
      "male: 0.005\n",
      "black: 0.007\n",
      "asian: 0.013\n"
     ]
    }
   ],
   "source": [
    "robust = PanelOLS(df.coll, x).fit(cov_type='robust',use_lsdv=True)\n",
    "se_rob = robust.std_errors\n",
    "print(\"Robust standard errors for exogenous variables\")\n",
    "print('constant:',np.round(se_rob[0],3))\n",
    "print('merit:',np.round(se_rob[1],3))\n",
    "print('male:',np.round(se_rob[2],3))\n",
    "print('black:',np.round(se_rob[3],3))\n",
    "print('asian:',np.round(se_rob[4],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual estimation of beta\n",
    "df = pd.read_csv(\"fullmeritaiddata.csv\")\n",
    "state_num = sorted(df['state'].unique().tolist())\n",
    "year_seq = sorted(df['year'].unique().tolist())\n",
    "s_dummy = [] \n",
    "i = 0\n",
    "while i<len(state_num):\n",
    "    s_dummy.append(np.where(df['state'] == state_num[i], 1, 0))\n",
    "    i += 1\n",
    "    if i > len(state_num):\n",
    "        break\n",
    "s_dummy = pd.DataFrame(np.asmatrix(s_dummy).T,columns =state_num)\n",
    "\n",
    "y_dummy = [] \n",
    "i = 0\n",
    "while i<len(year_seq):\n",
    "    y_dummy.append(np.where(df['year'] == year_seq[i], 1, 0))\n",
    "    i += 1\n",
    "    if i > len(year_seq):\n",
    "        break\n",
    "y_dummy = pd.DataFrame(np.asmatrix(y_dummy).T,columns =year_seq) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dummy = s_dummy.drop(11,axis=1)\n",
    "year_dummy = y_dummy.drop(1989, axis=1)\n",
    "new_df = pd.concat([df,state_dummy,year_dummy],axis=1)\n",
    "y = np.asmatrix(df['coll']).T\n",
    "exog_vars = new_df.drop(['coll','chst','year','state'],axis=1)\n",
    "x = sm.add_constant(exog_vars)\n",
    "x = np.asmatrix(x)\n",
    "b = inv(x.T*x)*x.T*y\n",
    "print('The estimated parameters')\n",
    "print('constant:',np.round(np.asscalar(b[0,]),3))\n",
    "print('merit:',np.round(np.asscalar(b[1,]),3))\n",
    "print('male:',np.round(np.asscalar(b[2,]),3))\n",
    "print('black:',np.round(np.asscalar(b[3,]),3))\n",
    "print('asian:',np.round(np.asscalar(b[4,]),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual estimation of the robust standard errors\n",
    "e = y - x*b\n",
    "sigma2 = np.asscalar(np.divide((e.T*e),(len(y)-len(b))))\n",
    "vcov = sigma2*inv(x.T*x)\n",
    "stderr = sqrt(diag(vcov))\n",
    "e2 = np.power(e,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.zeros(shape=(66,66))\n",
    "for i in range(len(e2)):\n",
    "    e_row = np.asscalar(e2[i])\n",
    "    x_row = x[i,]\n",
    "    product = e_row * x_row.T*x_row\n",
    "    S += product\n",
    "whcov = inv(x.T*x)*S*inv(x.T*x)\n",
    "robust_se = sqrt(diag(whcov))\n",
    "print('Robust standard errors')\n",
    "print('constant:',np.asscalar(robust_se[0,]))\n",
    "print('merit:',np.asscalar(robust_se[1,]))\n",
    "print('male:',np.asscalar(robust_se[2,]))\n",
    "print('black:',np.asscalar(robust_se[3,]))\n",
    "print('asian:',np.asscalar(robust_se[4,]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard regression using all data but weighted so that each state in each year gets the same weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the weight for state $i$ at year $j$ equal $w_{ij}$ so letting each state in each year get the same weight implies\n",
    "\\begin{equation}\n",
    "w_{11,1993} = w_{12,1993} ... = w_{95,1993} \\\\\n",
    "w_{11,2000} = w_{12,2000}... = w_{95,2000}\\\\\n",
    "...\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"fullmeritaiddata.csv\")\n",
    "year = pd.Categorical(df['year'])\n",
    "state = pd.Categorical(df['state'])\n",
    "df = df.set_index(['state','year'])\n",
    "df['year'] = year\n",
    "df['state'] = state\n",
    "state_num = sorted(df['state'].unique().tolist())\n",
    "year_seq = sorted(df['year'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "denom = []\n",
    "for j in year_seq:\n",
    "    d = len(df[df['year']==j])\n",
    "    denom.append(d)\n",
    "weights_t = []\n",
    "for i in range(len(denom)):\n",
    "    e = 1 / denom[i]\n",
    "    weights_t.append(e)\n",
    "#weights_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_df = pd.DataFrame()\n",
    "for i in range(len(year_seq)):\n",
    "    ydf = df[df['year'] == year_seq[i]].astype(float)\n",
    "    wdf = weights_t[i]*ydf[['coll','merit','male','black','asian']]\n",
    "    w_df = w_df.append(wdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_df = w_df.reset_index(level=['state','year'])\n",
    "year = pd.Categorical(weighted_df['year'])\n",
    "state = pd.Categorical(weighted_df['state'])\n",
    "weighted_df = weighted_df.set_index(['state','year'])\n",
    "weighted_df['year'] = year\n",
    "weighted_df['state'] = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated parameters from regression with equal weights for each state in each year\n",
      "constant: 0.005\n",
      "merit: 0.027\n",
      "male: -0.083\n",
      "black: -0.148\n",
      "asian: 0.173\n"
     ]
    }
   ],
   "source": [
    "exog = ['merit','male','black','asian','state','year']\n",
    "x = sm.add_constant(weighted_df[exog])\n",
    "equal_w = PooledOLS(weighted_df.coll, x).fit\\\n",
    "(cov_type='clustered',cluster_entity=True)\n",
    "param_w = equal_w.params\n",
    "print(\"Estimated parameters from regression with equal \\\n",
    "weights for each state in each year\")\n",
    "print('constant:',np.round(param_w[0],3))\n",
    "print('merit:',np.round(param_w[1],3))\n",
    "print('male:',np.round(param_w[2],3))\n",
    "print('black:',np.round(param_w[3],3))\n",
    "print('asian:',np.round(param_w[4],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual estimation\n",
    "weighted_df = w_df.reset_index(level=['state', 'year'])\n",
    "s_dummy = [] \n",
    "i = 0\n",
    "while i<len(state_num):\n",
    "    s_dummy.append(np.where(weighted_df['state'] == state_num[i], 1, 0))\n",
    "    i += 1\n",
    "    if i > len(state_num):\n",
    "        break\n",
    "s_dummy = pd.DataFrame(np.asmatrix(s_dummy).T,columns =state_num)\n",
    "\n",
    "y_dummy = [] \n",
    "i = 0\n",
    "while i<len(year_seq):\n",
    "    y_dummy.append(np.where(weighted_df['year'] == year_seq[i], 1, 0))\n",
    "    i += 1\n",
    "    if i > len(year_seq):\n",
    "        break\n",
    "y_dummy = pd.DataFrame(np.asmatrix(y_dummy).T,columns =year_seq) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dummy = s_dummy.drop(11,axis=1)\n",
    "year_dummy = y_dummy.drop(1989, axis=1)\n",
    "new_df = pd.concat([weighted_df,state_dummy,year_dummy],axis=1)\n",
    "y = np.asmatrix(weighted_df['coll']).T\n",
    "exog_vars = new_df.drop(['coll','year','state'],axis=1)\n",
    "x = sm.add_constant(exog_vars)\n",
    "x = np.asmatrix(x)\n",
    "b = inv(x.T*x)*x.T*y\n",
    "print('The estimated parameters')\n",
    "print('constant:',np.asscalar(b[0,]))\n",
    "print('merit:',np.asscalar(b[1,]))\n",
    "print('male:',np.asscalar(b[2,]))\n",
    "print('black:',np.asscalar(b[3,]))\n",
    "print('asian:',np.asscalar(b[4,]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression on all data but with the mean of all variable by $state \\times year$ with robust standard errors and clustered by state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"fullmeritaiddata.csv\")\n",
    "state_num = sorted(df['state'].unique().tolist())\n",
    "year_seq = sorted(df['year'].unique().tolist())\n",
    "# coll_avg = df.groupby(['year','state'])['coll'].mean()\n",
    "def columnavg(column):\n",
    "    col_avg = []\n",
    "    for i in state_num:\n",
    "        data = column[df['state'] == i]\n",
    "        for j in year_seq:\n",
    "            col_data = data[df['year'] == j]\n",
    "            avg = mean(col_data)\n",
    "            col_avg.append(avg)\n",
    "    return col_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_avg = np.asarray(columnavg(df['coll']))\n",
    "merit_avg = np.asarray(columnavg(df['merit']))\n",
    "male_avg = np.asarray(columnavg(df['male']))\n",
    "black_avg = np.asarray(columnavg(df['black']))\n",
    "asian_avg = np.asarray(columnavg(df['asian']))\n",
    "year = np.asarray(np.tile(year_seq,51))\n",
    "state = np.asarray(np.repeat(state_num,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.stack((coll_avg,merit_avg,male_avg,\n",
    "        black_avg,asian_avg,year,state), axis=1)\n",
    "meandf = pd.DataFrame(mean, columns = ['coll',\n",
    "'merit','male','black','asian','year','state'])\n",
    "year = pd.Categorical(meandf['year'])\n",
    "state = pd.Categorical(meandf['state'])\n",
    "meandf = meandf.set_index(['state','year'])\n",
    "meandf['year'] = year\n",
    "meandf['state'] = state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimation with clustered standard errors by state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated parameters\n",
      "constant: 0.473\n",
      "merit: 0.05\n",
      "male: -0.11\n",
      "black: -0.168\n",
      "asian: -0.008\n"
     ]
    }
   ],
   "source": [
    "exog = ['merit','male','black','asian','state','year']\n",
    "x = sm.add_constant(meandf[exog])\n",
    "mean_clust_state = PooledOLS(meandf.coll, x).fit\\\n",
    "(cov_type='clustered',cluster_entity=True)\n",
    "parameters = mean_clust_state.params\n",
    "se_ms = mean_clust_state.std_errors\n",
    "print(\"Estimated parameters\")\n",
    "print('constant:',np.round(parameters[0],3))\n",
    "print('merit:',np.round(parameters[1],3))\n",
    "print('male:',np.round(parameters[2],3))\n",
    "print('black:',np.round(parameters[3],3))\n",
    "print('asian:',np.round(parameters[4],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered standard errors by state\n",
      "constant: 0.0006205634598635754\n",
      "merit: 0.013582542845276444\n",
      "male: 0.057504338030208234\n",
      "black: 0.07345129878399519\n",
      "asian: 0.14929280330387235\n"
     ]
    }
   ],
   "source": [
    "print(\"Clustered standard errors by state\")\n",
    "print('constant:',se_ms[0])\n",
    "print('merit:',se_ms[1])\n",
    "print('male:',se_ms[2])\n",
    "print('black:',se_ms[3])\n",
    "print('asian:',se_ms[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimation with robust standard errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robust standard errors for exogenous variables\n",
      "constant: 0.044675795608873484\n",
      "merit: 0.013790906367855025\n",
      "male: 0.055264034758472295\n",
      "black: 0.07524576550883985\n",
      "asian: 0.19017266800840946\n"
     ]
    }
   ],
   "source": [
    "mean_robust = PooledOLS(meandf.coll, x).fit(cov_type='robust')\n",
    "se_mr = mean_robust.std_errors\n",
    "print(\"Robust standard errors for exogenous variables\")\n",
    "print('constant:',se_mr[0])\n",
    "print('merit:',se_mr[1])\n",
    "print('male:',se_mr[2])\n",
    "print('black:',se_mr[3])\n",
    "print('asian:',se_mr[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted regression of part c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression using the mean of all values by $state \\times year$ but weighting each state in each year equally, so using the weights found in part b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_df = pd.DataFrame()\n",
    "for i in range(len(year_seq)):\n",
    "    ydf = meandf[meandf['year'] == year_seq[i]].astype(float)\n",
    "    wdf = weights_t[i]*ydf[['coll','merit','male','black','asian']]\n",
    "    ind_df = ind_df.append(wdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_w_df = ind_df.reset_index(level=['state', 'year'])\n",
    "year = pd.Categorical(mean_w_df['year'])\n",
    "state = pd.Categorical(mean_w_df['state'])\n",
    "mean_w_df = mean_w_df.set_index(['state','year'])\n",
    "mean_w_df['year'] = year\n",
    "mean_w_df['state'] = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated parameters\n",
      "constant: 0.005525033597786941\n",
      "merit: 0.04310606428141104\n",
      "male: -0.12114553746433597\n",
      "black: -0.18097761958777\n",
      "asian: 0.08600217844654579\n"
     ]
    }
   ],
   "source": [
    "exog = ['merit','male','black','asian','state','year']\n",
    "x = sm.add_constant(mean_w_df[exog])\n",
    "mean_w = PooledOLS(mean_w_df.coll, x).fit(cov_type='robust')\n",
    "parameters = mean_w.params\n",
    "se_ms = mean_w.std_errors\n",
    "print(\"Estimated parameters\")\n",
    "print('constant:',parameters[0])\n",
    "print('merit:',parameters[1])\n",
    "print('male:',parameters[2])\n",
    "print('black:',parameters[3])\n",
    "print('asian:',parameters[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robust standard errors\n",
      "constant: 0.0006205634598635754\n",
      "merit: 0.013582542845276444\n",
      "male: 0.057504338030208234\n",
      "black: 0.07345129878399519\n",
      "asian: 0.14929280330387235\n"
     ]
    }
   ],
   "source": [
    "print(\"Robust standard errors\")\n",
    "print('constant:',se_ms[0])\n",
    "print('merit:',se_ms[1])\n",
    "print('male:',se_ms[2])\n",
    "print('black:',se_ms[3])\n",
    "print('asian:',se_ms[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression using the mean of all values by $state \\times year$ but using weights representative of the sample of individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_num = sorted(df['state'].unique().tolist())\n",
    "year_seq = sorted(df['year'].unique().tolist())\n",
    "weight_s = []\n",
    "for i in year_seq:\n",
    "    ydf = df[df['year'] == i].astype(float)\n",
    "    for j in state_num:\n",
    "        sdf = ydf[ydf['state'] == j].astype(float)\n",
    "        wei = len(sdf) / len(ydf)\n",
    "        weight_s.append(wei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = meandf.sort_values(by=['year','state']).astype(float)\n",
    "weight_s = np.asmatrix(weight_s).T\n",
    "weightedcol = np.multiply(weight_s.astype(float),sorted_df[['coll',\n",
    "                                'merit','male','black','asian']])\n",
    "col_weights = pd.DataFrame(weightedcol,columns =['coll','merit','male','black','asian'])\n",
    "ys = sorted_df[['year','state']]\n",
    "ys = ys.reset_index(drop=True)\n",
    "df_weights = pd.concat([col_weights,ys],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated parameters for exogenous variables from standard regression with state and year FE\n",
      "constant: 0.002\n",
      "merit: 0.048\n",
      "male: 0.465\n",
      "black: 0.224\n",
      "asian: 0.831\n"
     ]
    }
   ],
   "source": [
    "weight_meandf =  df_weights.set_index(['year','state'])\n",
    "weight_meandf['year'] = year\n",
    "weight_meandf['state'] = state\n",
    "exog = ['merit','male','black','asian','state','year']\n",
    "x = sm.add_constant(weight_meandf[exog])\n",
    "ind_weight = PooledOLS(weight_meandf.coll, x).fit\\\n",
    "(cov_type='robust')\n",
    "parameters = ind_weight.params\n",
    "se = ind_weight.std_errors\n",
    "print(\"Estimated parameters for exogenous variables \\\n",
    "from standard regression with state and year FE\")\n",
    "print('constant:',np.round(parameters[0],3))\n",
    "print('merit:',np.round(parameters[1],3))\n",
    "print('male:',np.round(parameters[2],3))\n",
    "print('black:',np.round(parameters[3],3))\n",
    "print('asian:',np.round(parameters[4],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all different estimations, the sign for merit remain positive implying that receiving merit increases the likelihood of being enrolled in college. The lowest value for merit is under the specification that each state in each year has equal weights and the highest is the estimation with the mean of all variables. The estimation with mean of all variables and mean with representative weights are both higher than the standard regression estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event study looking at the effects of the merit aid program before and after it was implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"fullmeritaiddata.csv\")\n",
    "year = pd.Categorical(df['year'])\n",
    "state = pd.Categorical(df['state'])\n",
    "df = df.set_index(['state','year'])\n",
    "df['year'] = year\n",
    "df['state'] = state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the states that received treatment i.e. merit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merit states [71, 58, 64, 59, 85, 72, 57, 61, 88, 34]\n"
     ]
    }
   ],
   "source": [
    "meritdf = df[df['merit'] == 1]\n",
    "meritdf = meritdf.sort_values(by=['year'])\n",
    "merit_st = meritdf['state'].unique().tolist()\n",
    "print(\"Merit states\",merit_st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the years that the treatment was implemented in the states that received the treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year\n",
       "71  1991\n",
       "58  1993\n",
       "64  1996\n",
       "59  1997\n",
       "85  1997\n",
       "72  1998\n",
       "57  1998\n",
       "61  1999\n",
       "88  2000\n",
       "34  2000"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"fullmeritaiddata.csv\")\n",
    "merit_year = []\n",
    "for i in merit_st:\n",
    "    merit_year.append(df[(df['merit'] == 1) & (df['state'] == i)]['year'].min())\n",
    "\n",
    "merit_start = pd.DataFrame({'year': merit_year}, index=merit_st)\n",
    "merit_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the year right before the treatment year for the states that implemented the merit treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year\n",
       "71  1990\n",
       "58  1992\n",
       "64  1995\n",
       "59  1996\n",
       "85  1996\n",
       "72  1997\n",
       "57  1997\n",
       "61  1998\n",
       "88  1999\n",
       "34  1999"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_merit_year = []\n",
    "for i in merit_st:\n",
    "    pre_merit_year.append(df[(df['merit'] == 0) & (df['state'] == i)]['year'].max())\n",
    "\n",
    "pre_merit = pd.DataFrame({'year': pre_merit_year}, index=merit_st)\n",
    "pre_merit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effect of merit can be estimated by taking the difference in means of $coll$. The first difference is between the merit states after implementing merit and before so I will take the mean of $coll$ for states that implemented merit before and after implementation and take the difference in the means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_df = []\n",
    "for i in merit_st:\n",
    "    post_df.append(df[(df['state']==i)&(df['merit']==1)&\n",
    "    (df['year']==merit_start.loc[i,'year'])].groupby(['year'])['coll'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df = []\n",
    "for i in merit_st:\n",
    "    pre_df.append(df[(df['state']==i)&(df['merit']==0)&\n",
    "    (df['year']==pre_merit.loc[i,'year'])].groupby(['year'])['coll'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_coll = []\n",
    "for i in range(len(post_df)):\n",
    "    post_coll.append(np.asscalar(np.asmatrix(post_df[i])))\n",
    "    \n",
    "pre_coll = []\n",
    "for i in range(len(pre_df)):\n",
    "    pre_coll.append(np.asscalar(np.asmatrix(pre_df[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_coll_df = pd.DataFrame(post_coll)\n",
    "pre_coll_df = pd.DataFrame(pre_coll)\n",
    "treat_df = pd.DataFrame({'Posttreat mean coll': np.round(post_coll, 4),\n",
    "                           'Pretreat mean coll': np.round(pre_coll, 4)},\n",
    "                          index=merit_st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The differences in mean from the pretreateament and posttreatment is calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Posttreat mean coll</th>\n",
       "      <th>Pretreat mean coll</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2708</td>\n",
       "      <td>0.1292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.3793</td>\n",
       "      <td>0.3556</td>\n",
       "      <td>0.0237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.4773</td>\n",
       "      <td>0.3659</td>\n",
       "      <td>0.1114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.4567</td>\n",
       "      <td>0.3361</td>\n",
       "      <td>0.1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>-0.0133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.3889</td>\n",
       "      <td>0.3651</td>\n",
       "      <td>0.0238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.5405</td>\n",
       "      <td>0.4857</td>\n",
       "      <td>0.0548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.4211</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>-0.0179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.4074</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.4724</td>\n",
       "      <td>0.5154</td>\n",
       "      <td>-0.0430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Posttreat mean coll  Pretreat mean coll    diff\n",
       "71               0.4000              0.2708  0.1292\n",
       "58               0.3793              0.3556  0.0237\n",
       "64               0.4773              0.3659  0.1114\n",
       "59               0.4567              0.3361  0.1206\n",
       "85               0.3200              0.3333 -0.0133\n",
       "72               0.3889              0.3651  0.0238\n",
       "57               0.5405              0.4857  0.0548\n",
       "61               0.4211              0.4390 -0.0179\n",
       "88               0.4074              0.3333  0.0741\n",
       "34               0.4724              0.5154 -0.0430"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treat_df['diff'] = treat_df['Posttreat mean coll'] - treat_df['Pretreat mean coll']\n",
    "treat_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
